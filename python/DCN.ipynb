{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutinal Networks (DCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow / Keras\n",
    "import tensorflow as tf # used to access argmax function\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout # for adding Concolutional and densely-connected NN layers.\n",
    "\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "\n",
    "# Sklearn\n",
    "import sklearn # for model evaluation\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
    "from sklearn.metrics import classification_report # for model evaluation metrics\n",
    "from sklearn.preprocessing import OrdinalEncoder # for encoding labels\n",
    "\n",
    "# Visualization\n",
    "import cv2 # for ingesting images\n",
    "print('OpenCV: %s' % cv2.__version__) # print version\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt # for showing images\n",
    "print('matplotlib: %s' % matplotlib.__version__) # print version\n",
    "\n",
    "#GUI\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from turtle import title\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "# Other utilities\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assign main directory to a variable\n",
    "main_dir=os.path.dirname(sys.path[0])\n",
    "# print(main_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Load and Process Caltech101 image dataset\n",
    "- Source and Licence: http://www.vision.caltech.edu/Image_Datasets/Caltech101/\n",
    "- Required Refrence: L. Fei-Fei, R. Fergus and P. Perona. Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories. IEEE. CVPR 2004, Workshop on Generative-Model Based Vision. 2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the location of images after you have downloaded them\n",
    "ImgLocation=main_dir+\"/data/101_ObjectCategories/\"\n",
    "\n",
    "# List image categories we are interested in\n",
    "LABELS = set([\"dandelions\", \"lotus\", \"orchids\", \"peony\", \"sunflower\"])\n",
    "\n",
    "# Create two lists to contain image paths and image labels\n",
    "ImagePaths=[]\n",
    "ListLabels=[]\n",
    "for label in LABELS:\n",
    "    for image in list(os.listdir(ImgLocation+label)):\n",
    "        ImagePaths=ImagePaths+[ImgLocation+label+\"/\"+image]\n",
    "        ListLabels=ListLabels+[label]\n",
    "        \n",
    "# Load images and resize to be a fixed 128x128 pixels, ignoring original aspect ratio\n",
    "data=[]\n",
    "for img in ImagePaths:\n",
    "    image = cv2.imread(img)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    data.append(image)\n",
    "    \n",
    "# Convert image data to numpy array and standardize values (divide by 255 since RGB values ranges from 0 to 255)\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "\n",
    "# Show data shape\n",
    "print(\"Shape of whole data: \", data.shape)\n",
    "\n",
    "# Convert Labels list to numpy array\n",
    "LabelsArray=np.array(ListLabels)\n",
    "\n",
    "# Encode labels \n",
    "enc = OrdinalEncoder()\n",
    "y=enc.fit_transform(LabelsArray.reshape(-1,1))\n",
    "\n",
    "\n",
    "# ---- Create training and testing samples ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=0)\n",
    "y_train=y_train.reshape(-1,1)\n",
    "y_test=y_test.reshape(-1,1)\n",
    "\n",
    "# Print shapes\n",
    "# Note, model input must have a four-dimensional shape [samples, rows, columns, channels]\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display a few images from our the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images of 10 flowers in the training set and their true labels\n",
    "fig, axs = plt.subplots(2, 5, sharey=False, tight_layout=True, figsize=(12,6), facecolor='white')\n",
    "n=0\n",
    "for i in range(0,2):\n",
    "    for j in range(0,5):\n",
    "        axs[i,j].matshow(X_train[n])\n",
    "        axs[i,j].set(title=enc.inverse_transform(y_train)[n])\n",
    "        n=n+1\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Train a Deep Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Tensorflow Keras Documentation (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout):\n",
    "The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Step 1 - Specify the structure of a Neural Network\n",
    "#--- Define a Model\n",
    "model = Sequential(name=\"Flower CNN Model\") # Model\n",
    "\n",
    "\n",
    "#--- Input Layer \n",
    "# Specify input shape [rows, columns, channels]\n",
    "model.add(Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3]), name='Input-Layer')) # Input Layer - need to speicfy the shape of inputs\n",
    "\n",
    "\n",
    "#--- First Set of Convolution, Max Pooling and Droput Layers (all parameters shown)\n",
    "model.add(Conv2D(filters=16, # Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "                kernel_size=(3,3), # An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "                strides=(1,1), # Default=(1,1), An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
    "                padding='valid', # Default='valid', \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. When padding=\"same\" and strides=1, the output has the same size as the input.\n",
    "                data_format=None, # Default=None, A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch_size, height, width, channels) while channels_first corresponds to inputs with shape (batch_size, channels,height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be channels_last.\n",
    "                dilation_rate=(1, 1), # Default=(1, 1), an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n",
    "                groups=1, # Default=1, A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with filters / groups filters. The output is the concatenation of all the groups results along the channel axis. Input channels and filters must both be divisible by groups.\n",
    "                activation='relu', # Default=None, Activation function to use. If you don't specify anything, no activation is applied (see keras.activations).\n",
    "                use_bias=True, # Default=True. \n",
    "                kernel_initializer='glorot_uniform', # Default='glorot_uniform', Initializer for the kernel weights matrix (see keras.initializers).\n",
    "                bias_initializer='zeros', # Default='zeros', Initializer for the bias vector (see keras.initializers).\n",
    "                kernel_regularizer=None, # Default=None, Regularizer function applied to the kernel weights matrix (see keras.regularizers).\n",
    "                bias_regularizer=None, # Default=None, Regularizer function applied to the bias vector (see keras.regularizers).\n",
    "                activity_regularizer=None, # Default=None, Regularizer function applied to the output of the layer (its \"activation\") (see keras.regularizers).\n",
    "                kernel_constraint=None, # Default=None, Constraint function applied to the kernel matrix (see keras.constraints).\n",
    "                bias_constraint=None, # Default=None, Constraint function applied to the bias vector (see keras.constraints).\n",
    "                name='2D-Convolutional-Layer-1') # Name of the layer (optional)\n",
    "        ) # Convolutional Layer, relu activation used\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2), # Default=(2,2), integer or tuple of 2 integers, window size over which to take the maximum. (2, 2) will take the max value over a 2x2 pooling window. If only one integer is specified, the same window length will be used for both dimensions.\n",
    "                strides=(2,2), # Default=None, Integer, tuple of 2 integers, or None. Strides values. Specifies how far the pooling window moves for each pooling step. If None, it will default to pool_size.\n",
    "                padding='valid', # Default='valid', One of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
    "                data_format=None, # Default=None, A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). \n",
    "                name='2D-MaxPool-Layer-1')\n",
    "        ) # Max Pooling Layer,\n",
    "\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-1')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Second Set of Convolution, Max Pooling and Droput Layers \n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', name='2D-Convolutional-Layer-2')) # Convolutional Layer\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid', name='2D-MaxPool-Layer-2')) # Second Max Pooling Layer,\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-2')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Third Set of Convolution, Max Pooling and Droput Layers\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name='2D-Convolutional-Layer-3')) # Convolutional Layer\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name='2D-MaxPool-Layer-3')) # Second Max Pooling Layer,\n",
    "model.add(Dropout(0.2, name='Dropout-Layer-3')) # Dropout Layer\n",
    "\n",
    "\n",
    "#--- Feed-Forward Densely Connected Layer and Output Layer (note, flattening is required to convert from 2D to 1D shape)\n",
    "model.add(Flatten(name='Flatten-Layer')) # Flatten the shape so we can feed it into a regular densely connected layer\n",
    "model.add(Dense(16, activation='relu', name='Hidden-Layer-1', kernel_initializer='HeNormal')) # Hidden Layer, relu(x) = max(x, 0)\n",
    "model.add(Dense(5, activation='softmax', name='Output-Layer')) # Output Layer, softmax(x) = exp(x) / tf.reduce_sum(exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### Step 2 - Compile keras model\n",
    "model.compile(optimizer='adam', # default='rmsprop', an algorithm to be used in backpropagation\n",
    "        loss='SparseCategoricalCrossentropy', # Loss function to be optimized. A string (name of loss function), or a tf.keras.losses.Loss instance.\n",
    "        metrics=['Accuracy'], # List of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a tf.keras.metrics.Metric instance. \n",
    "        loss_weights=None, # default=None, Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs.\n",
    "        weighted_metrics=None, # default=None, List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.\n",
    "        run_eagerly=None, # Defaults to False. If True, this Model's logic will not be wrapped in a tf.function. Recommended to leave this as None unless your Model cannot be run inside a tf.function.\n",
    "        steps_per_execution=None # Defaults to 1. The number of batches to run during each tf.function call. Running multiple batches inside a single tf.function call can greatly improve performance on TPUs or small models with a large Python overhead.\n",
    "    )\n",
    "\n",
    "\n",
    "##### Step 3 - Fit keras model on the dataset\n",
    "history = model.fit(X_train, # input data\n",
    "                    y_train, # target data\n",
    "                    batch_size=1, # Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "                    epochs=25, # default=1, Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided\n",
    "                    verbose=1, # default='auto', ('auto', 0, 1, or 2). Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases, but 2 when used with ParameterServerStrategy.\n",
    "                    callbacks=None, # default=None, list of callbacks to apply during training. See tf.keras.callbacks\n",
    "                    validation_split=0.0, # default=0.0, Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. \n",
    "                    #validation_data=(X_test, y_test), # default=None, Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                    shuffle=True, # default=True, Boolean (whether to shuffle the training data before each epoch) or str (for 'batch').\n",
    "                    class_weight=None, # default=None, Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "                    sample_weight=None, # default=None, Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only).\n",
    "                    initial_epoch=0, # Integer, default=0, Epoch at which to start training (useful for resuming a previous training run).\n",
    "                    steps_per_epoch=None, # Integer or None, default=None, Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. \n",
    "                    validation_steps=None, # Only relevant if validation_data is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch.\n",
    "                    validation_batch_size=None, # Integer or None, default=None, Number of samples per validation batch. If unspecified, will default to batch_size.\n",
    "                    validation_freq=1, # default=1, Only relevant if validation data is provided. If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. validation_freq=2 runs validation every 2 epochs.\n",
    "                    max_queue_size=10, # default=10, Used for generator or keras.utils.Sequence input only. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n",
    "                    workers=1, # default=1, Used for generator or keras.utils.Sequence input only. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1.\n",
    "                    use_multiprocessing=False, # default=False, Used for generator or keras.utils.Sequence input only. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. \n",
    "                )\n",
    "\n",
    "# Save the model for the project\n",
    "model.save('my_model.h5')\n",
    "\n",
    "##### Step 4 - Use model to make predictions\n",
    "# Note, we need to pass model output through argmax to convert from probability to label\n",
    "# Also, we convert output from tensor to numpy array\n",
    "# Predict class labels on training data\n",
    "pred_labels_tr = np.array(tf.math.argmax(model.predict(X_train),axis=1))\n",
    "# Predict class labels on a test data\n",
    "pred_labels_te = np.array(tf.math.argmax(model.predict(X_test),axis=1))\n",
    "\n",
    "\n",
    "##### Step 5 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('------------------------- Model Summary -------------------------')\n",
    "model.summary() # print model summary\n",
    "print(\"\")\n",
    "\n",
    "print(\"\")\n",
    "print('------------------------- Encoded Names -------------------------')\n",
    "for i in range(0,len(enc.categories_[0])):\n",
    "    print(i,\": \",enc.categories_[0][i])\n",
    "print(\"\")\n",
    "\n",
    "print('------------------ Evaluation on Training Data ------------------')\n",
    "# Print the last value in the evaluation metrics contained within history file\n",
    "for item in history.history:\n",
    "    print(\"Final\", item, \":\", history.history[item][-1])\n",
    "print(\"\")\n",
    "# Print classification report\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print(\"\")\n",
    "\n",
    "print('-------------------- Evaluation on Test Data --------------------')\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Check which category the model will put my dog in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ingest the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the image\n",
    "# mydog = cv2.imread(main_dir+\"/data/sunflower.jpg\")\n",
    "\n",
    "# # Display the image\n",
    "# plt.matshow(mydog)\n",
    "# plt.show()\n",
    "\n",
    "border_effects = {\n",
    "    \"raised\": tk.RAISED,\n",
    "}\n",
    "\n",
    "# initialise the GUI window\n",
    "window = tk.Tk()\n",
    "window.geometry('800x600')\n",
    "window.title('Flower Recognition')\n",
    "window.configure(background='#CDCDCD')\n",
    "window.columnconfigure(0, minsize=250)\n",
    "window.rowconfigure([0, 1], minsize=100)\n",
    "\n",
    "label = tk.Label(window, background='#CDCDCD', font=('arial', 15, 'bold'))\n",
    "sign_image = tk.Label(window)\n",
    "\n",
    "for relief_name, relief in border_effects.items():\n",
    "    frame = tk.Frame(master=window, relief=relief, bg=\"light blue\")\n",
    "    frame.pack(fill=tk.X)\n",
    "    label = tk.Label(master=frame, text=\"CHOOSE AN IMAGE\", bg=\"light blue\", justify =['center'], padx=200, pady=150, font=('arial', 30, 'bold'))\n",
    "    label.grid()\n",
    "\n",
    "def upload_image():\n",
    "    global uploaded\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    uploaded = cv2.imread(file_path)\n",
    "\n",
    "button = tk.Button(frame, text=\"SELECT AN IMAGE\", fg=\"black\",justify =['center'], command=upload_image, padx=10, pady=15, font=('arial', 11, 'bold'))\n",
    "button.grid()\n",
    "\n",
    "frame1 = tk.Frame(master=window, height=900, bg=\"light blue\")\n",
    "frame1.pack(fill=tk.X)\n",
    "window.mainloop()\n",
    "\n",
    "plt.matshow(uploaded)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prep the image and make a prediction using our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize \n",
    "uploaded = cv2.resize(uploaded, (128, 128))\n",
    "\n",
    "# Standardize (divide by 255 since RGB values ranges from 0 to 255)\n",
    "uploaded = uploaded / 255.0\n",
    "\n",
    "# The current shape of uploaded array is [rows, columns, channels].\n",
    "# Add extra dimension to make it [samples, rows, columns, channels] that is required by the model\n",
    "uploaded = uploaded[np.newaxis, ...]\n",
    "\n",
    "# Print shape\n",
    "print(\"Shape of the input: \", uploaded.shape)\n",
    "print(\"\")\n",
    "\n",
    "#----- Predict label of uploaded image -----\n",
    "# Note, we need to pass model output through argmax to convert from probability to label\n",
    "# Also, we convert output from tensor to numpy array\n",
    "# Finally, we do inverse transform to convert from encoded value to categorical label\n",
    "pred_uploaded = enc.inverse_transform(np.array(tf.math.argmax(model.predict(uploaded),axis=1)).reshape(-1, 1))\n",
    "print(\"DCN model prediction: \", pred_uploaded)\n",
    "\n",
    "\n",
    "#----- Show Probabilities of each prediction -----\n",
    "pred_probs=model.predict(uploaded)\n",
    "\n",
    "# Print in a nice format with label and probability next to each other\n",
    "print(\"\")\n",
    "print(\"Probabilities for each category:\")\n",
    "for i in range(0,len(enc.categories_[0])):\n",
    "    print(enc.categories_[0][i], \" : \", pred_probs[0][i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "39e1d90bc9060d2ab7b05f557ead79f8c6bd372beba210d0a22c76db53c89137"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
